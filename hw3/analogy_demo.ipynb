{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec = KeyedVectors.load_word2vec_format('word2vec/vectors_400.bin', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('krali', 0.46581345796585083),\n",
       " ('kralice', 0.46316829323768616),\n",
       " ('kralicesi', 0.4226829409599304),\n",
       " ('kralin', 0.4212174713611603),\n",
       " ('edwardin', 0.41212937235832214),\n",
       " ('richardin', 0.41065317392349243),\n",
       " ('krallari', 0.4024549126625061),\n",
       " ('henrynin', 0.39439308643341064),\n",
       " ('charlesin', 0.3926564157009125),\n",
       " ('kralinin', 0.3692318797111511)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word2vec.save('word2vec.model')\n",
    "w2v_dim = 400\n",
    "word2vec.most_similar(positive=['anne', 'kral'], negative=['erkek'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_ds import *\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def get_and_clean(dataset):\n",
    "    df = pd.read_csv(\n",
    "        dataset, usecols=['comment', 'Label'], encoding='unicode_escape')\n",
    "\n",
    "    drop = []\n",
    "    for index, row in df.iterrows():\n",
    "        content = row['comment']\n",
    "        translator = str.maketrans(\n",
    "            string.punctuation, ' '*len(string.punctuation))\n",
    "        content = content.translate(translator)\n",
    "        content = preprocess(content)\n",
    "        df.loc[index, 'comment'] = content\n",
    "        if not df.loc[index, 'comment']:\n",
    "            drop.append(index)\n",
    "    df = df.drop(index=drop)\n",
    "    return np.array(df['comment']), np.array(df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7991,), (7991,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_train, y_train = get_and_clean('dataset/train.csv')\n",
    "words_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2665,), (2665,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_test, y_test = get_and_clean('dataset/test.csv')\n",
    "words_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.228896, -0.147009, -1.931883, -1.020285, -2.318674,  0.210398,\n",
       "       -2.645644,  1.263047, -0.38474 , -0.289636,  0.500422,  2.070905,\n",
       "       -0.662991, -2.315848,  0.645493,  2.275743, -1.737326, -0.538942,\n",
       "       -2.024382,  0.485932,  3.148136, -0.922693, -0.925424,  1.049409,\n",
       "        0.449243, -1.0477  , -0.266813,  0.912633, -0.063486,  0.306128,\n",
       "        0.579044, -0.750976, -1.502728, -0.536388,  0.782174, -1.448138,\n",
       "       -1.695138,  3.203634, -3.157739, -1.638112, -0.105682,  1.814888,\n",
       "        0.045683, -1.917891, -0.29747 , -0.281818,  0.219515, -1.420733,\n",
       "        0.199821, -0.88874 , -0.432684,  2.162875, -0.999417,  0.418473,\n",
       "       -0.699038, -0.873585,  0.810698, -0.856115, -2.023203,  1.560693,\n",
       "       -1.435654, -0.576036, -0.29178 ,  2.598387, -0.776041, -2.541595,\n",
       "        0.366221, -1.811885,  1.092941, -1.364043, -1.710791, -0.187191,\n",
       "       -0.083885, -1.928778,  0.786471,  3.330691, -1.521363, -1.427381,\n",
       "        4.178517,  0.407285,  1.873843, -0.26251 ,  0.033188, -0.375833,\n",
       "       -1.907803, -0.39145 ,  1.693806,  1.732674, -4.170681, -2.441906,\n",
       "        0.650283, -0.652392,  0.114257, -2.203338,  0.0315  , -1.023078,\n",
       "       -1.916603,  1.744224,  0.389569,  0.373402,  0.360001, -0.744354,\n",
       "        0.885404, -0.826423, -1.155918, -0.04842 ,  0.843071,  0.270152,\n",
       "        1.486139, -0.917333, -0.842776,  0.405209,  0.085816, -0.020364,\n",
       "       -2.275576, -1.120884, -0.887026, -0.919599,  2.048433, -0.66049 ,\n",
       "       -1.773872, -0.567118, -0.097155,  0.704899,  0.211327,  2.472015,\n",
       "       -1.741493, -2.126389,  0.854972,  1.404491, -1.374577, -0.520142,\n",
       "        0.72792 , -1.732607, -1.067121,  1.402128,  0.518538,  0.704103,\n",
       "       -0.552883, -0.01889 , -2.766744, -1.421703, -0.447156, -2.01941 ,\n",
       "       -0.529004,  1.854532,  0.609244, -0.189383, -1.021089,  1.139188,\n",
       "       -0.062398, -0.110874, -0.405926,  0.272031,  0.136138,  1.430988,\n",
       "       -0.832605,  0.009661, -0.570734,  1.11431 , -1.719628,  0.059652,\n",
       "       -1.929401, -2.147784,  0.077271,  0.499143, -0.879846,  0.037903,\n",
       "        0.422778,  1.005124,  1.720965, -2.518106,  1.123668, -3.18402 ,\n",
       "        2.591148,  1.334621, -1.219536, -1.588285,  1.26316 , -1.733034,\n",
       "       -0.283853,  0.012791, -1.088827, -0.816762,  1.639696,  2.493347,\n",
       "        0.308798, -1.102364,  0.47374 ,  0.651523,  0.507136, -0.439721,\n",
       "       -0.744415,  1.296074,  0.536458,  1.154016,  0.446089, -0.30302 ,\n",
       "       -0.481435, -0.811354,  1.509333, -1.211887, -1.666024,  0.486504,\n",
       "        0.487036, -1.307108, -2.788506, -0.575541, -1.390171,  0.269105,\n",
       "        0.460487, -1.075268,  0.119248, -0.472348,  0.141619, -2.278311,\n",
       "       -0.437532, -1.258826, -0.51861 ,  2.895372,  0.096721,  3.36315 ,\n",
       "        1.34362 ,  0.553948,  1.731956,  0.063665,  1.586805,  0.731976,\n",
       "        0.680711, -1.48187 ,  0.188747, -0.184618,  0.487616, -1.708542,\n",
       "       -0.05455 , -0.793474,  2.759321, -1.433934,  0.552602, -1.677917,\n",
       "        1.300298,  3.676177,  0.973839, -0.097658, -0.024223,  2.616785,\n",
       "        0.084174, -3.157761,  0.924803, -0.631001,  2.347155, -0.345542,\n",
       "       -0.234947, -0.626016, -0.508775, -0.84301 ,  1.565349, -0.744066,\n",
       "       -0.995892,  2.639111,  0.787879, -0.421765, -0.499006, -2.062881,\n",
       "       -2.614017,  1.326034, -0.77843 , -0.840806, -0.435595,  1.265868,\n",
       "        1.834771, -1.174528,  1.997895, -2.276864, -1.672144,  1.189192,\n",
       "        1.30243 , -1.332567, -0.036933,  1.831986, -0.101501,  1.920146,\n",
       "       -1.173488,  1.172948, -0.777819,  0.329796, -0.705898,  1.910207,\n",
       "       -1.835043, -0.656413,  2.442797, -2.393317,  1.58181 , -0.366629,\n",
       "        1.666882,  2.430259,  1.982508, -0.265466,  1.236125, -0.260198,\n",
       "        0.809935,  1.158241,  1.181865, -1.591582,  1.036392, -2.631776,\n",
       "        0.511055, -3.522662,  3.115573, -1.668747,  2.827943,  0.538422,\n",
       "        0.645349, -0.916492,  2.034189,  1.22868 , -2.922307, -1.569538,\n",
       "        2.229473,  0.102498,  3.046172,  0.470642,  1.382711,  0.12103 ,\n",
       "        1.247553,  0.34597 ,  2.282749, -0.799275, -1.229524,  0.361973,\n",
       "       -0.543352, -0.49573 ,  3.016295,  1.523704,  0.892666, -1.483058,\n",
       "        0.231018,  1.909972,  0.551999,  1.389854,  0.361026,  1.480711,\n",
       "        1.05167 ,  0.166061,  1.333427, -1.493865, -0.921661, -1.445985,\n",
       "       -0.675461,  0.830655,  2.439617, -2.015511,  0.484086,  0.818105,\n",
       "       -1.90861 , -0.113441, -2.045147, -1.93544 , -0.734291, -0.458404,\n",
       "       -0.113254,  1.629903, -0.754557, -0.018616,  1.274186, -1.075922,\n",
       "        0.40392 ,  0.708813,  0.273346,  0.733404, -2.139531, -0.065076,\n",
       "        1.869014,  1.167201, -0.279156,  1.125593,  2.517758,  1.675882,\n",
       "       -0.91831 , -1.072031,  0.578395,  0.807327,  0.227275, -0.878839,\n",
       "       -1.422416,  1.93436 , -1.571658, -1.109951,  0.430273, -0.567716,\n",
       "       -0.265575,  2.156903, -1.703154, -0.859773, -1.257204,  1.565994,\n",
       "        1.049108, -0.172915,  1.733593,  2.183518], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec['biri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extrem(v, get='min'):\n",
    "    vmin = v[0]\n",
    "    if get == 'min':\n",
    "        func = np.minimum\n",
    "    elif get == 'max':\n",
    "        func = np.maximum\n",
    "    for vi in v:\n",
    "        vmin = func(vmin, vi)\n",
    "    return vmin\n",
    "\n",
    "def feature_vector(v):\n",
    "    return np.concatenate((get_extrem(v, get='min'), get_extrem(v, get='max')))\n",
    "\n",
    "def min_max_transform(X, word2vec):\n",
    "    new_X = []\n",
    "    for x in X:\n",
    "        v = [word2vec[w] for w in x.split()]\n",
    "        new_X.append(feature_vector(v))\n",
    "    return np.array(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_transform(X, word2vec):\n",
    "    new_X = []\n",
    "    for x in X:\n",
    "        v = [word2vec[w] for w in x.split()]\n",
    "        w = np.zeros(w2v_dim)\n",
    "        for vi in v:\n",
    "            w += vi\n",
    "        w /= len(vi)\n",
    "        new_X.append(w)\n",
    "    return np.array(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict \n",
    "\n",
    "def tfidf_transform(X, word2vec):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf.fit(X)\n",
    "    max_idf = max(tfidf.idf_)\n",
    "    word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "    new_X = []\n",
    "    return np.array([\n",
    "                np.mean([word2vec[w] * word2weight[w]\n",
    "                         for w in words.split()], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def benchmark(transform):\n",
    "    X_train = transform(words_train, word2vec)\n",
    "    X_test = transform(words_test, word2vec)\n",
    "    print(X_train.shape, X_test.shape)\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('f1 score:', f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7991, 800) (2665, 800)\n",
      "f1 score: 0.6656660412757974\n"
     ]
    }
   ],
   "source": [
    "benchmark(min_max_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7991, 400) (2665, 400)\n",
      "f1 score: 0.6731707317073171\n"
     ]
    }
   ],
   "source": [
    "benchmark(mean_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7991, 400) (2665, 400)\n",
      "f1 score: 0.7166979362101313\n"
     ]
    }
   ],
   "source": [
    "benchmark(tfidf_transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
