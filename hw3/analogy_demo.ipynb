{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('word2vec/vectors.bin', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('krali', 0.6292586326599121),\n",
       " ('kralice', 0.6282593607902527),\n",
       " ('norodom', 0.6125580668449402),\n",
       " ('sihanouk', 0.5838896632194519),\n",
       " ('kralicesi', 0.5752500891685486),\n",
       " ('silmariene', 0.5721966028213501),\n",
       " ('edwardin', 0.5614503622055054),\n",
       " ('teoderik', 0.5602492094039917),\n",
       " ('prensi', 0.557105302810669),\n",
       " ('hirodes', 0.5560301542282104)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('word2vec.model')\n",
    "model.most_similar(positive=['anne', 'kral'], negative=['erkek'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_ds import *\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def get_and_clean(dataset):\n",
    "    df = pd.read_csv(\n",
    "        dataset, usecols=['comment', 'Label'], encoding='unicode_escape')\n",
    "\n",
    "    drop = []\n",
    "    for index, row in df.iterrows():\n",
    "        content = row['comment']\n",
    "        translator = str.maketrans(\n",
    "            string.punctuation, ' '*len(string.punctuation))\n",
    "        content = content.translate(translator)\n",
    "        content = preprocess(content)\n",
    "        df.loc[index, 'comment'] = content\n",
    "        if not df.loc[index, 'comment']:\n",
    "            drop.append(index)\n",
    "    df = df.drop(index=drop)\n",
    "    return np.array(df['comment']), np.array(df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7991,), (7991,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = get_and_clean('dataset/train.csv')\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2665,), (2665,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = get_and_clean('dataset/test.csv')\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.329586,  0.502957, -1.970287, -0.780498,  0.719182, -1.566812,\n",
       "        2.826463, -2.613646,  2.6055  ,  2.190009,  0.01035 , -1.141106,\n",
       "        1.139917,  1.692133,  5.008232, -2.969589,  1.641621,  1.685976,\n",
       "        1.296329,  3.856552,  0.542349,  0.862442,  1.865268, -2.799784,\n",
       "       -2.092626,  3.27122 , -0.301047, -3.995167,  1.798686,  2.143213,\n",
       "       -3.792131, -1.586872, -1.419663, -0.63752 ,  5.930891,  1.433477,\n",
       "        4.245801, -0.761896, -4.553113, -2.136155,  0.828079, -3.103901,\n",
       "       -1.347521, -1.637442,  2.763175,  0.976209, -1.601628,  2.946443,\n",
       "       -0.342828,  0.122558, -5.228163,  2.380381,  2.421279, -0.268938,\n",
       "       -1.324287, -0.817046,  2.177338, -1.676326,  2.14197 , -0.539436,\n",
       "        3.881288,  0.595402,  1.408362, -2.283121, -5.496751, -0.061185,\n",
       "       -0.103148,  2.258779, -0.134703, -3.748308, -0.289   , -3.733705,\n",
       "       -2.39455 , -1.509682,  5.108567, -0.455409,  1.978857, -0.288489,\n",
       "        0.428164, -1.433106, -2.658688, -3.45943 , -2.06523 ,  0.091382,\n",
       "       -4.240468, -3.465017, -0.63008 ,  1.519397,  0.383676,  0.082377,\n",
       "        3.152498,  0.840854, -1.890208, -1.0026  , -2.220978, -0.811845,\n",
       "       -0.27728 ,  2.652963,  5.494907,  0.15598 ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['biri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extrem(v, get='min'):\n",
    "    vmin = v[0]\n",
    "    if get == 'min':\n",
    "        func = np.minimum\n",
    "    elif get == 'max':\n",
    "        func = np.maximum\n",
    "    for vi in v:\n",
    "        vmin = func(vmin, vi)\n",
    "    return vmin\n",
    "\n",
    "def feature_vector(v):\n",
    "    return np.concatenate((get_extrem(v, get='min'), get_extrem(v, get='max')))\n",
    "\n",
    "def to_feature_set(X):\n",
    "    new_X = []\n",
    "    for i, x in enumerate(X):\n",
    "        v = [model[w] for w in x.split()]\n",
    "        new_X.append(feature_vector(v))\n",
    "    return np.array(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7991, 200)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = to_feature_set(X_train)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2665, 200)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = to_feature_set(X_test)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6517823639774859\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(a, y_train)\n",
    "y_pred = model.predict(b)\n",
    "print(f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
